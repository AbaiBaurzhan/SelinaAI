# rag.py
# RAG: PDF/DOCX/XLSX/JPG/PNG ‚Üí —á–∞–Ω–∫–∏ ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ ‚Üí –ø–æ–∏—Å–∫ top-k + –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–π—Å–∞

from __future__ import annotations

import os
import re
import json
import time
import base64
import sqlite3
from pathlib import Path
from typing import Callable, List, Tuple, Optional, Dict, Any

import numpy as np
import fitz  # PyMuPDF
from openai import OpenAI

from telegram import Update
from telegram.ext import ContextTypes
from telegram.constants import ChatAction

# DOCX/XLSX
from docx import Document as DocxDocument
from openpyxl import load_workbook

DB_PATH = Path(__file__).with_name("state.db")
UPLOADS_DIR = Path(__file__).parent / "uploads"
UPLOADS_DIR.mkdir(exist_ok=True)

# ----- —Ä–µ–∑–æ–ª–≤–µ—Ä –∫–ª—é—á–∞ OpenAI (–∑–∞–¥–∞—ë—Ç—Å—è –∏–∑ main.py) -----
_KeyResolver: Optional[Callable[[], Optional[str]]] = None
def configure_key_resolver(func: Callable[[], Optional[str]]) -> None:
    global _KeyResolver
    _KeyResolver = func
def _resolve_api_key() -> Optional[str]:
    if _KeyResolver:
        key = _KeyResolver()
        if key:
            return key
    return os.getenv("OPENAI_API_KEY")

# ----- –ë–î RAG -----
def db_init_rag() -> None:
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS documents (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT,
            type TEXT,
            path TEXT,
            created_at INTEGER
        )
    """)
    cur.execute("""
        CREATE TABLE IF NOT EXISTS chunks (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            document_id INTEGER,
            idx INTEGER,
            text TEXT,
            embedding_json TEXT,
            FOREIGN KEY(document_id) REFERENCES documents(id)
        )
    """)
    # –ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –ø—Ä–∞–π—Å–∞
    cur.execute("""
        CREATE TABLE IF NOT EXISTS catalog_items (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            document_id INTEGER,
            line_no INTEGER,
            name TEXT,
            price_value REAL,
            currency TEXT,
            raw_line TEXT,
            created_at INTEGER,
            FOREIGN KEY(document_id) REFERENCES documents(id)
        )
    """)
    con.commit()
    con.close()

# =======================
#        –ü–ê–†–°–ï–†–´
# =======================
def pdf_to_text(pdf_path: str) -> str:
    doc = fitz.open(pdf_path)
    texts: List[str] = []
    for page in doc:
        texts.append(page.get_text("text"))
    return "\n".join(texts)

def docx_to_text(path: str) -> str:
    doc = DocxDocument(path)
    parts: List[str] = []
    for p in doc.paragraphs:
        t = p.text.strip()
        if t:
            parts.append(t)
    for table in doc.tables:
        for row in table.rows:
            cells = [c.text.strip() for c in row.cells]
            line = " | ".join([c for c in cells if c])
            if line:
                parts.append(line)
    return "\n".join(parts)

def xlsx_to_text(path: str) -> str:
    wb = load_workbook(path, read_only=True, data_only=True)
    parts: List[str] = []
    for sheet in wb.worksheets:
        parts.append(f"[–õ–∏—Å—Ç: {sheet.title}]")
        for row in sheet.iter_rows(values_only=True):
            cells = [str(c).strip() for c in row if c is not None and str(c).strip() != ""]
            if cells:
                parts.append(" | ".join(cells))
    return "\n".join(parts)

# ===== OpenAI Vision: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π =====
def image_to_text_openai(image_path: str, api_key: str, model: str = "gpt-4o-mini") -> str:
    with open(image_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    lower = image_path.lower()
    if lower.endswith(".png"):
        mime = "image/png"
    elif lower.endswith(".jpg") or lower.endswith(".jpeg"):
        mime = "image/jpeg"
    else:
        mime = "image/jpeg"

    client = OpenAI(api_key=api_key)
    prompt = (
        "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∞–π—Å–∞/–º–µ–Ω—é. "
        "–°–æ—Ö—Ä–∞–Ω–∏ –ø–æ—Ä—è–¥–æ–∫ —Å—Ç—Ä–æ–∫ –∏ –∫–æ–ª–æ–Ω–æ–∫. –ù–µ –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç."
    )
    data_url = f"data:{mime};base64,{b64}"

    resp = client.chat.completions.create(
        model=model,
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": data_url}},
            ],
        }],
        temperature=0.0,
    )
    text = resp.choices[0].message.content or ""
    return text.strip()

# =======================
#   –ß–ê–ù–ö–ò/–≠–ú–ë–ï–î–î–ò–ù–ì–ò
# =======================
def chunk_text(text: str, max_chars: int = 1200, overlap: int = 150) -> List[str]:
    text = " ".join(text.split())
    chunks: List[str] = []
    start = 0
    n = len(text)
    while start < n:
        end = min(n, start + max_chars)
        chunk = text[start:end]
        if chunk.strip():
            chunks.append(chunk)
        if end == n:
            break
        start = max(0, end - overlap)
    return chunks

def embed_texts(client: OpenAI, texts: List[str]) -> List[List[float]]:
    resp = client.embeddings.create(
        model="text-embedding-3-small",
        input=texts,
    )
    return [e.embedding for e in resp.data]

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    na = np.linalg.norm(a); nb = np.linalg.norm(b)
    if na == 0 or nb == 0:
        return 0.0
    return float(np.dot(a, b) / (na * nb))

def retrieve_top_k(question: str, k: int = 4) -> List[Tuple[str, float]]:
    key = _resolve_api_key()
    if not key:
        return []
    client = OpenAI(api_key=key)
    q_emb = client.embeddings.create(
        model="text-embedding-3-small",
        input=[question],
    ).data[0].embedding
    qv = np.array(q_emb, dtype=np.float32)

    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute("SELECT text, embedding_json FROM chunks")
    rows = cur.fetchall()
    con.close()

    scored: List[Tuple[str, float]] = []
    for t, ej in rows:
        vec = np.array(json.loads(ej), dtype=np.float32)
        scored.append((t, cosine_sim(qv, vec)))
    scored.sort(key=lambda x: x[1], reverse=True)
    return scored[:k]

# =======================
#  –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ê–ô–°–ê
# =======================
_CURRENCY_MAP = {
    "‚Ç∏": "KZT", "—Ç–≥": "KZT", "—Ç–µ–Ω–≥–µ": "KZT", "kzt": "KZT",
    "‚ÇΩ": "RUB", "—Ä—É–±": "RUB", "—Ä—É–±.": "RUB", "—Ä—É–±–ª–µ–π": "RUB", "rub": "RUB",
    "$": "USD", "usd": "USD",
    "‚Ç¨": "EUR", "eur": "EUR",
}

# —Ü–µ–Ω–∞: 2 500, 2.500, 2,500.00, 2500, 2 500 —Ç–≥, 2500‚Ç∏, 25.000 —Ä—É–±, 9,90 ‚Ç¨
_PRICE_RE = re.compile(
    r"""(?P<num>
            \d{1,3}(?:[ .]\d{3})*(?:[.,]\d{1,2})?   # 1 234,56  | 1.234,56 | 1 234 | 1234.50
            |
            \d+(?:[.,]\d{1,2})?                     # 1234 | 1234,50
        )
        \s*
        (?P<cur>‚Ç∏|—Ç–≥|—Ç–µ–Ω–≥–µ|kzt|‚ÇΩ|—Ä—É–±\.?|—Ä—É–±–ª–µ–π|rub|\$|usd|‚Ç¨|eur)? # –≤–∞–ª—é—Ç–∞ (–æ–ø—Ü.)
    """,
    re.IGNORECASE | re.VERBOSE
)

def _normalize_number(num_str: str) -> float:
    s = num_str.replace(" ", "").replace("\u00A0", "")
    # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç "1.234,56" (–µ–≤—Ä–æ‚Äë—Å—Ç–∏–ª—å): –∑–∞–º–µ–Ω–∏–º —Ç—ã—Å—è—á–∏ '.' –∏ –¥–µ—Å—è—Ç—ã–µ ',' ‚Üí '.'
    if re.search(r"\d+\.\d{3}(?:\.|\b)", s) and "," in s:
        s = s.replace(".", "").replace(",", ".")
    else:
        # –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ –∑–∞–º–µ–Ω–∏–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –¥–ª—è –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        # fallback: —É–±–∏—Ä–∞–µ–º –≤—Å—ë –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ —Ç–æ—á–∫–∏
        s = re.sub(r"[^0-9.]", "", s)
        return float(s) if s else 0.0

def _normalize_currency(cur: Optional[str]) -> Optional[str]:
    if not cur:
        return None
    c = cur.lower().strip().strip(".")
    return _CURRENCY_MAP.get(c, cur.upper())

def extract_catalog_items(text: str) -> List[Dict[str, Any]]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–∞–π—Å–∞:
    - –ò—â–µ–º —á–∏—Å–ª–æ + –æ–ø—Ü. –≤–∞–ª—é—Ç—É
    - –ù–∞–∑–≤–∞–Ω–∏–µ ‚Äî —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ –±–µ–∑ —Ü–µ–Ω—ã –∏–ª–∏ —á–∞—Å—Ç—å –¥–æ/–ø–æ—Å–ª–µ —Ü–µ–Ω—ã
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ {name, price_value, currency, raw_line, line_no}
    """
    items: List[Dict[str, Any]] = []
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    for i, line in enumerate(lines, start=1):
        m = _PRICE_RE.search(line)
        if not m:
            continue
        num = _normalize_number(m.group("num"))
        cur = _normalize_currency(m.group("cur"))

        # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: –±–µ—Ä—ë–º ¬´–≤—Å—ë, –∫—Ä–æ–º–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø—Ä–∞–π—Å‚Äë—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞¬ª
        name = (line[:m.start()] + " " + line[m.end():]).strip()
        # –ß–∏—Å—Ç–∏–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã: –ø–∞–π–ø—ã, –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        name = re.sub(r"\s{2,}", " ", name)
        name = name.strip(" |:-‚Äî")

        # –ï—Å–ª–∏ –∏–º—è –ø—É—Å—Ç–æ–µ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ –∏–º—è
        if not name and i > 1:
            prev = lines[i - 2]
            if not _PRICE_RE.search(prev) and len(prev) <= 120:
                name = prev

        if not name:
            name = "–ü–æ–∑–∏—Ü–∏—è"

        items.append({
            "line_no": i,
            "name": name,
            "price_value": num,
            "currency": cur or "KZT",  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é KZT, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
            "raw_line": line,
        })
    return items

def db_insert_catalog_items(document_id: int, items: List[Dict[str, Any]]) -> int:
    if not items:
        return 0
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    now = int(time.time())
    for it in items:
        cur.execute("""
            INSERT INTO catalog_items(document_id, line_no, name, price_value, currency, raw_line, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            document_id, it["line_no"], it["name"], it["price_value"], it["currency"], it["raw_line"], now
        ))
    con.commit()
    con.close()
    return len(items)

# =======================
#     –ò–ù–î–ï–ö–°–ê–¶–ò–Ø
# =======================
def _index_text_blocks(doc_name: str, doc_type: str, local_path: Path, parts: List[str], key: str) -> int:
    client = OpenAI(api_key=key)
    vectors = embed_texts(client, parts)

    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    cur.execute(
        "INSERT INTO documents(name, type, path, created_at) VALUES(?,?,?,?)",
        (doc_name, doc_type, str(local_path), int(time.time())),
    )
    doc_id = cur.lastrowid

    for i, (t, vec) in enumerate(zip(parts, vectors)):
        cur.execute(
            "INSERT INTO chunks(document_id, idx, text, embedding_json) VALUES(?,?,?,?)",
            (doc_id, i, t, json.dumps(vec)),
        )

    con.commit()
    con.close()
    return doc_id

# =======================
#  –•–ï–ù–î–õ–ï–† –ó–ê–ì–†–£–ó–ö–ò
# =======================
async def upload_doc(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç PDF/DOCX/XLSX/JPG/PNG –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç, –ø–∞—Ä—Å–∏—Ç, –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∏ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ—Ç –ø—Ä–∞–π—Å‚Äë–ø–æ–∑–∏—Ü–∏–∏.
    """
    key = _resolve_api_key()
    if not key:
        await update.message.reply_text(
            "‚ùå –ù–µ—Ç –∫–ª—é—á–∞ OpenAI. "
            "–î–æ–±–∞–≤—å —Å–≤–æ–π –∫–ª—é—á —á–µ—Ä–µ–∑ /set_openai –∏–ª–∏ —É–∫–∞–∂–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–π –≤ touch.env (OPENAI_API_KEY=...)."
        )
        return

    msg_doc = update.message.document if update.message else None
    if not msg_doc:
        await update.message.reply_text("–ü—Ä–∏—à–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç (PDF/DOCX/XLSX/JPG/PNG) –∫–∞–∫ —Ñ–∞–π–ª.")
        return

    fname = (msg_doc.file_name or "").lower()
    supported = any(fname.endswith(ext) for ext in (".pdf", ".docx", ".xlsx", ".jpg", ".jpeg", ".png"))
    if not supported:
        await update.message.reply_text("–°–µ–π—á–∞—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º: PDF, DOCX, XLSX, JPG, PNG.")
        return

    await update.message.chat.send_action(ChatAction.UPLOAD_DOCUMENT)

    # –°–∫–∞—á–∏–≤–∞–µ–º
    tg_file = await context.bot.get_file(msg_doc.file_id)
    local_path = UPLOADS_DIR / msg_doc.file_name
    await tg_file.download_to_drive(str(local_path))

    # –ü–∞—Ä—Å–∏–Ω–≥
    try:
        if fname.endswith(".pdf"):
            raw_text = pdf_to_text(str(local_path)); doc_type = "pdf"
        elif fname.endswith(".docx"):
            raw_text = docx_to_text(str(local_path)); doc_type = "docx"
        elif fname.endswith(".xlsx"):
            raw_text = xlsx_to_text(str(local_path)); doc_type = "xlsx"
        elif fname.endswith((".jpg", ".jpeg", ".png")):
            raw_text = image_to_text_openai(str(local_path), api_key=key, model="gpt-4o-mini"); doc_type = "image"
        else:
            await update.message.reply_text("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç."); return

        if not raw_text or not raw_text.strip():
            await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞.")
            return

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        parts = chunk_text(raw_text)
        if not parts:
            await update.message.reply_text("–¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á—ë–Ω, –Ω–æ –ø—É—Å—Ç –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.")
            return
        doc_id = _index_text_blocks(msg_doc.file_name, doc_type, local_path, parts, key)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–π—Å‚Äë–ø–æ–∑–∏—Ü–∏–π
        items = extract_catalog_items(raw_text)
        saved = db_insert_catalog_items(doc_id, items)

        await update.message.reply_text(
            f"‚úÖ –ó–∞–≥—Ä—É–∑–∏–ª –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–ª —Ñ–∞–π–ª: {msg_doc.file_name}\n"
            f"–¢–∏–ø: {doc_type.upper()} | –ß–∞–Ω–∫–æ–≤: {len(parts)} | id={doc_id}\n"
            f"üßæ –ü—Ä–∞–π—Å‚Äë–ø–æ–∑–∏—Ü–∏–π —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {saved}"
        )
    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
